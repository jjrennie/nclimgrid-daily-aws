{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting NOAA's nClimGrid Daily Stored in AWS\n",
    "## Written By Jared Rennie\n",
    "\n",
    "Ever see a plot like this?\n",
    "\n",
    "<img src='nclimgrid-conus_tmax_20210724.png' width='615' height='463' alt='so cool!'>\n",
    "\n",
    "And wanted to make one yourself? Wonder where the data came from? Are you sick and tired of seeing \"Made by @jjrennie\" and wanted to plot something better? Well now is your chance!\n",
    "\n",
    "### What You Need\n",
    "\n",
    "First off, the entire codebase works in Python... sort of. \n",
    "\n",
    "You will need the following programs installed: \n",
    "- Python\n",
    "- s3fs | numpy | xarray | geopandas | rioxarray | matplotlib | cartopy | shapely | metpy | h5netcdf | h5py \n",
    "    \n",
    "The \"easiest\" way is to install these is by installing <a href='https://www.anaconda.com/' target=\"_blank\">Anaconda</a>, and then applying <a href='https://conda-forge.org/' target=\"_blank\">conda-forge</a>. Afterward, then you can install the above packages. \n",
    "\n",
    "### Importing Packages\n",
    "Assuming you did the above, it should (in theory) import everything no problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import sys, time, datetime, math, calendar\n",
    "import s3fs\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from shapely.geometry import mapping\n",
    "from metpy.plots import USCOUNTIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a date and element\n",
    "\n",
    "If you made it this far, great!\n",
    "\n",
    "<a href='https://www.ncei.noaa.gov/products/land-based-station/nclimgrid-daily' target='blank'>NOAA's nClimGrid Daily </a> is a gridded, 5km dataset of daily temperature (max,min,avg) and precipitation for the Contiguous United States going back to 1951. There are gridded netCDF versions, and also values aggregated to certain regions (county, state, NWS Forecast Office). If you ever wanted to investigate the data, you can check them out at these locations:\n",
    "\n",
    "- **WWW:** <a href='https://www.ncei.noaa.gov/pub/data/daily-grids/v1-0-0/' target = 'blank'>https://www.ncei.noaa.gov/pub/data/daily-grids/v1-0-0/</a>\n",
    "- **AWS:** s3://noaa-nclimgrid-daily-pds/v1-0-0/\n",
    "\n",
    "This block of code will utilize the AWS bucket and take one day, and one element, and plot it in Python. We have to submit arguments to indicate the day and element we want. **Let's pick a random day of no importance (or pick one yourself)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert Arguments Here\n",
    "year= 2019  \n",
    "month= 2\n",
    "day= 3\n",
    "element= 'prcp' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next block will set up some date and plotting info, based on the arguments chosen above.\n",
    "\n",
    "Feel free to play with the date formatting, color schemes, and bounds I've used. \n",
    "\n",
    "<a href='https://colorbrewer2.org/' target='blank'>ColorBrewer</a> is an excellent website to help one figure out color schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some Info Based on Date\n",
    "day_counter=int(day)\n",
    "current_date=\"%04i%02i%02i\" % (int(year),int(month),int(day))\n",
    "current_month=\"%04i%02i\" % (int(year),int(month))\n",
    "\n",
    "# Set info based on Element\n",
    "if element == \"tmax\" or element == \"tmin\" or element == \"tavg\":\n",
    "    unit='°F'\n",
    "    if element=='tmax':\n",
    "        element_name='Maximum Temperature'\n",
    "    if element=='tmin':\n",
    "        element_name='Minimum Temperature'    \n",
    "    if element=='tavg':\n",
    "        element_name='Average Temperature'\n",
    "\n",
    "    # Set Up Color Map\n",
    "    cmap='RdYlBu_r' \n",
    "    bounds=np.array([0,10,20,30,40,50,60,70,80,90,100,110])   \n",
    "        \n",
    "if element == \"prcp\":\n",
    "    unit='inches'  \n",
    "    element_name='Precipitation'\n",
    "\n",
    "    # Set Up Color Map\n",
    "    cmap='YlGnBu' \n",
    "    bounds=np.array([0.01,0.10,0.25,0.50,0.75,1.00,2.00,3.00,4.00], dtype='f')\n",
    "\n",
    "# Set up some other Plotting info\n",
    "dpi=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok let's read some data.\n",
    "\n",
    "nClimGrid Daily is updated each day, so you should be able to get the most recent data. This block of code will attempt to find the necessary data in the AWS bucket. The netCDF files are stored by month. Since this data is publicly available via the <a href=\"https://www.noaa.gov/information-technology/big-data\" target=\"blank\">NOAA Open Data Dissemination (NODD) Project</a>, anonymous data read should be fine (`anon=True`)\n",
    "\n",
    "Also, since the data is updated frequently, some of the most recent files indicate 'prelim' for preliminary, and finalized versions are noted as 'scaled.' This block of code will read in the data from AWS, knowing this discrepancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# READ IN DATA FROM AWS\n",
    "\n",
    "# Open File System\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "# Get Specific File Based on Inputs\n",
    "aws_year=\"%04i\" % (int(year))\n",
    "aws_month=\"%02i\" % (int(month))\n",
    "aws_version='prelim'\n",
    "aws_url='s3://noaa-nclimgrid-daily-pds/v1-0-0/grids/'+aws_year+'/ncdd-'+aws_year+aws_month+'-grd-'+aws_version+'.nc'\n",
    "\n",
    "# Read in Data\n",
    "print('READING IN nClimGrid DATA FROM AWS: ',aws_url)\n",
    "try:\n",
    "    aws_file=s3.open(aws_url)\n",
    "except:\n",
    "    aws_version='scaled'\n",
    "    aws_url='s3://noaa-nclimgrid-daily-pds/v1-0-0/grids/'+aws_year+'/ncdd-'+aws_year+aws_month+'-grd-'+aws_version+'.nc'\n",
    "    print('FAILED, TRYING THIS URL: ',aws_url)\n",
    "    aws_file=s3.open(aws_url)\n",
    "\n",
    "data_monthly = xr.open_dataset(aws_file)\n",
    "print(\"\\tSUCCESS!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the data\n",
    "You may get a warning after reading the data, but if you've made it this far, congrats, you read in data from AWS! \n",
    "\n",
    "Well, let's made sure it was read in correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The netCDF file should have lat (596 points) and lon (1385 points) dimensions, with a time dimension indicating how many days in the month. \n",
    "\n",
    "You'll also notice that the lat/lon values are noted in degrees. This will be important later. \n",
    "\n",
    "Let's go ahead and get the lat/lon values, as well as the data for a particular day. This data is originally in metric (C and mm) units, so we will convert to imperial units (F and inches) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Lat/Lons\n",
    "nclimgrid_lats=data_monthly.lat.values\n",
    "nclimgrid_lons=data_monthly.lon.values\n",
    "\n",
    "# Get Data, Convert from metric\n",
    "if element == 'prcp':\n",
    "    conus_value=(data_monthly[element].values[day_counter-1,:,:] * 0.0393701)  \n",
    "else:\n",
    "    conus_value=(data_monthly[element].values[day_counter-1,:,:] * 1.8) + 32."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's see how the data looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conus_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gah! Nan's? Well Don't worry, there's data (I promise). To prove it, let's pick one gridpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conus_value[300,300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See? Nothing to Worry About. \n",
    "\n",
    "Now for the fun part...\n",
    "\n",
    "### Plotting the data!\n",
    "\n",
    "But before we get there, we want YOU to be the creator of the final product (not me!) So let's give credit to yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author='Not Jared Rennie'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's plot. The following block of code does the following:\n",
    "\n",
    "- Set up the colorbar\n",
    "- Create the Figure in the Lambert Conformal Projection\n",
    "- Adjust the map to fit CONUS\n",
    "- Add boundaries such as US States\n",
    "- Plot the data we have aquired\n",
    "- Add colorbar and other info (including authorship!) \n",
    "- Show the results\n",
    "\n",
    "I would take a good look at this block. This is the result of months of trial and error to make this great! Feel free to tinker (if you're feeling confident)\n",
    "\n",
    "**PRO TIP**: This took me forever to realize, but since cartopy projections and transformations can be frustrating, I'm going to give you a piece of advice\n",
    "1. The projection you want the final output to be in is indicated here: \n",
    "\n",
    "`ax = fig.add_axes([0, 0, 1, 1], projection=ccrs.LambertConformal())`\n",
    "\n",
    "2. In order for the data to match to the projection indicated in 1. above, you must indicate what the projection of the data currently is when plotting: \n",
    "\n",
    "`ax.pcolormesh(nclimgrid_lons, nclimgrid_lats, conus_value,transform=ccrs.PlateCarree(),cmap=cmap,norm=norm,vmin=vmin,vmax=vmax)`\n",
    "\n",
    "In other words, we know the data is in a lat/lon projection, so using these two commands indicate that the data is in lat/lon `ccrs.PlateCarree()` and we want to re-project onto the map `ccrs.LanbertConformal()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# PLOTTING CONUS\n",
    "print(\"PLOTTING CONUS\")\n",
    "\n",
    "# Set Up Colorbar info\n",
    "vmin=np.min(bounds)\n",
    "vmax=np.max(bounds)\n",
    "extend='both'\n",
    "norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=256)\n",
    "cm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "cm.set_array(np.array(conus_value))\n",
    "cm.set_clim(vmin, vmax)\n",
    "\n",
    "# Set CONUS Bounds\n",
    "minLat = 22    \n",
    "maxLat = 50   \n",
    "minLon = -120 \n",
    "maxLon = -73 \n",
    "\n",
    "# Set Up Figure\n",
    "fig= plt.figure(num=1, figsize=(8,5), dpi=dpi, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0, 0, 1, 1], projection=ccrs.LambertConformal())\n",
    "ax.set_extent([minLon, maxLon, minLat, maxLat], crs=ccrs.Geodetic())\n",
    "ax.set_facecolor('#4a4a4a')\n",
    "\n",
    "# Add Boundaries\n",
    "ax.add_feature(cfeature.COASTLINE,linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS,linewidth=0.5)\n",
    "ax.add_feature(cfeature.STATES,linewidth=0.5)\n",
    "\n",
    "# Plot Data\n",
    "ax.pcolormesh(nclimgrid_lons, nclimgrid_lats, conus_value,transform=ccrs.PlateCarree(),cmap=cmap,norm=norm,vmin=vmin,vmax=vmax)\n",
    "\n",
    "# Add Colorbar\n",
    "cax = fig.add_axes([0.1, -0.035, 0.8, 0.03])\n",
    "cbar=plt.colorbar(cm, cax=cax,boundaries=bounds,orientation='horizontal',extend=extend,spacing='uniform')\n",
    "cbar.ax.tick_params(labelsize=15)\n",
    "cbar.set_label(unit,size=15)\n",
    "\n",
    "# Annotate Info On Graphic\n",
    "nclimgrid_max=\"%6.1f\" % np.nanmax(conus_value)\n",
    "nclimgrid_min=\"%6.1f\" % np.nanmin(conus_value)\n",
    "plt.annotate('Source: nClimGrid Daily\\nMade By: '+author,xy=(1.045, -3.51), xycoords='axes fraction', fontsize=7,color='black',horizontalalignment='right', verticalalignment='bottom')\n",
    "if element == \"prcp\":\n",
    "    plt.annotate('MAX: '+str(nclimgrid_max)+'\"\\nMIN: '+str(nclimgrid_min)+'\"',xy=(0.045, -3.51), xycoords='axes fraction', fontsize=7,color='black',horizontalalignment='right', verticalalignment='bottom')\n",
    "else:\n",
    "    plt.annotate('MAX: '+str(nclimgrid_max)+'°F\\nMIN: '+str(nclimgrid_min)+'°F',xy=(0.045, -3.51), xycoords='axes fraction', fontsize=7,color='black',horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "# Add Title and Save to File\n",
    "plt.suptitle('Daily '+element_name+' for '+current_date,size=17,color='black',y=1.05) \n",
    "plt.show() \n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You made a CONUS plot using NOAA data stored on AWS! Feel free to post on social media for the world to see!\n",
    "\n",
    "### Challenge: Clipping\n",
    "\n",
    "Now some of you might be thinking, \"Cool Cool, but I live in the Carolinas, and don't want to squint to see the data there. \n",
    "\n",
    "Well have no fear, we can do some GIS Style clipping to make it work! All in Python!\n",
    "\n",
    "First We have to organize the data we read in a little more. We know that the coordinates are in lat/lon coordinate reference system, so we need to indicate that (for the non-GIS folks, it's EPSG 4326). This is where rioxarray comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Spatial Configurations of nClimGrid Data (For Clipping Purposes)\n",
    "data_monthly=data_monthly.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "data_monthly=data_monthly.rio.write_crs('epsg:4326', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should have a New England shapefile associated with it. Let's read it in using geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Shapefile For Clipping Purposes\n",
    "shapefile_name='Carolinas'\n",
    "input_shapefile='input_shapefile/'+str(shapefile_name)+'_Merc.shp'\n",
    "geo_shapefile = gpd.read_file(input_shapefile)\n",
    "projection=geo_shapefile.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the Shapefile indicates it might be in the Mercator Projection ('Merc'), it doesn't hurt to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epsg:3395 is World Mercator. But note the that epsg values are different between the nClimGrid data and the Shapefile (4326 and 3395, respectively). Thankfully because we defined both, this should be taken care of when we clip.\n",
    "\n",
    "So, let's go ahead and clip and get the data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip CONUS Data By Shapefile\n",
    "data_monthly_clip=data_monthly.rio.clip(geo_shapefile.geometry.apply(mapping), geo_shapefile.crs, drop=False)\n",
    "\n",
    "# Get Data, Convert from metric\n",
    "if element == 'prcp':\n",
    "    conus_value=(data_monthly_clip[element].values[day_counter-1,:,:] * 0.0393701)  \n",
    "else:\n",
    "    conus_value=(data_monthly_clip[element].values[day_counter-1,:,:] * 1.8) + 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot again! To prove the clip worked, let's keep the same figure we had (CONUS) and see if New England data is the only part that is plotted.\n",
    "\n",
    "p.s. for those that are screaming \"pUt tHiS iN a fUnCtIoN\", I... didn't feel like it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# PLOTTING BASED ON SHAPEFILE\n",
    "print(\"PLOTTING BASED ON SHAPEFILE\")\n",
    "\n",
    "# Set Up Colorbar info\n",
    "vmin=np.min(bounds)\n",
    "vmax=np.max(bounds)\n",
    "extend='both'\n",
    "norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=256)\n",
    "cm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "cm.set_array(np.array(conus_value))\n",
    "cm.set_clim(vmin, vmax)\n",
    "\n",
    "# Set CONUS Bounds\n",
    "minLat = 22    \n",
    "maxLat = 50   \n",
    "minLon = -120 \n",
    "maxLon = -73 \n",
    "\n",
    "# Set Up Figure\n",
    "fig= plt.figure(num=1, figsize=(8,5), dpi=dpi, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0, 0, 1, 1], projection=ccrs.LambertConformal())\n",
    "ax.set_extent([minLon, maxLon, minLat, maxLat], crs=ccrs.Geodetic())\n",
    "ax.set_facecolor('#4a4a4a')\n",
    "\n",
    "# Add Boundaries\n",
    "ax.add_feature(cfeature.COASTLINE,linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS,linewidth=0.5)\n",
    "ax.add_feature(cfeature.STATES,linewidth=0.5)\n",
    "\n",
    "# Plot Data\n",
    "ax.pcolormesh(nclimgrid_lons, nclimgrid_lats, conus_value,transform=ccrs.PlateCarree(),cmap=cmap,norm=norm,vmin=vmin,vmax=vmax)\n",
    "\n",
    "# Add Colorbar\n",
    "cax = fig.add_axes([0.1, -0.035, 0.8, 0.03])\n",
    "cbar=plt.colorbar(cm, cax=cax,boundaries=bounds,orientation='horizontal',extend=extend,spacing='uniform')\n",
    "cbar.ax.tick_params(labelsize=15)\n",
    "cbar.set_label(unit,size=15)\n",
    "\n",
    "# Annotate Info On Graphic\n",
    "nclimgrid_max=\"%6.1f\" % np.nanmax(conus_value)\n",
    "nclimgrid_min=\"%6.1f\" % np.nanmin(conus_value)\n",
    "plt.annotate('Source: nClimGrid Daily\\nMade By: '+author,xy=(1.045, -3.51), xycoords='axes fraction', fontsize=7,color='black',horizontalalignment='right', verticalalignment='bottom')\n",
    "if element == \"prcp\":\n",
    "    plt.annotate('MAX: '+str(nclimgrid_max)+'\"\\nMIN: '+str(nclimgrid_min)+'\"',xy=(0.045, -3.51), xycoords='axes fraction', fontsize=7,color='black',horizontalalignment='right', verticalalignment='bottom')\n",
    "else:\n",
    "    plt.annotate('MAX: '+str(nclimgrid_max)+'°F\\nMIN: '+str(nclimgrid_min)+'°F',xy=(0.045, -3.51), xycoords='axes fraction', fontsize=7,color='black',horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "# Add Title and Save to File\n",
    "plt.suptitle('Daily '+element_name+' for '+current_date,size=17,color='black',y=1.05) \n",
    "plt.show() \n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check this plot vs the previous, but they should be the same (well, at least for New England)\n",
    "\n",
    "Also note that because we clipped the data, the Max/Min values on the bottom left are different.\n",
    "\n",
    "Now let's plot one more time, but change the map projection to Mercator, and zoom in on New England!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Shapefile Bounds\n",
    "minLat = 40    \n",
    "maxLat = 48   \n",
    "minLon = -74 \n",
    "maxLon = -66 \n",
    "\n",
    "# Set Up Figure\n",
    "fig= plt.figure(num=1, figsize=(8,8), dpi=dpi, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0, 0, 1, 1], projection=ccrs.Mercator())\n",
    "ax.set_extent([minLon, maxLon, minLat, maxLat], crs=ccrs.Geodetic())\n",
    "ax.set_facecolor('#4a4a4a')\n",
    "\n",
    "# Add Boundaries\n",
    "ax.add_feature(cfeature.COASTLINE,linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS,linewidth=0.5)\n",
    "ax.add_feature(cfeature.STATES,linewidth=0.5)\n",
    "\n",
    "# Plot Data\n",
    "ax.pcolormesh(nclimgrid_lons, nclimgrid_lats, conus_value,transform=ccrs.PlateCarree(),cmap=cmap,norm=norm,vmin=vmin,vmax=vmax)\n",
    "\n",
    "# Add Colorbar\n",
    "cax = fig.add_axes([0.1, -0.035, 0.8, 0.03])\n",
    "cbar=plt.colorbar(cm, cax=cax,boundaries=bounds,orientation='horizontal',extend=extend,spacing='uniform')\n",
    "cbar.ax.tick_params(labelsize=15)\n",
    "cbar.set_label(unit,size=15)\n",
    "\n",
    "# Annotate Info On Graphic\n",
    "nclimgrid_max=\"%6.1f\" % np.nanmax(conus_value)\n",
    "nclimgrid_min=\"%6.1f\" % np.nanmin(conus_value)\n",
    "plt.annotate('Source: nClimGrid Daily\\nMade By: '+author,xy=(1.045, -3.51), xycoords='axes fraction', fontsize=7,color='black',horizontalalignment='right', verticalalignment='bottom')\n",
    "if element == \"prcp\":\n",
    "    plt.annotate('MAX: '+str(nclimgrid_max)+'\"\\nMIN: '+str(nclimgrid_min)+'\"',xy=(0.045, -3.51), xycoords='axes fraction', fontsize=7,color='black',horizontalalignment='right', verticalalignment='bottom')\n",
    "else:\n",
    "    plt.annotate('MAX: '+str(nclimgrid_max)+'°F\\nMIN: '+str(nclimgrid_min)+'°F',xy=(0.045, -3.51), xycoords='axes fraction', fontsize=7,color='black',horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "# Add Title and Save to File\n",
    "plt.suptitle('Daily '+element_name+' for '+current_date,size=17,color='black',y=1.05) \n",
    "plt.show() \n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't it beautiful?\n",
    "\n",
    "**Congrats on completing this notebook! Now go forth and make better plots!**\n",
    "\n",
    "### Some other challenges you could try\n",
    "- One in theory could calculate diurnal temperature range, which is max minus min\n",
    "- How could one add county lines, or point data indicating cities. Could other shapefiles be added as layers?\n",
    "- There's other gridded data publicly available from the NOAA Big Data Project. Could one plot that as well?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
